{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "564ff549-5aba-42d9-b90d-ae7aae46c37e",
   "metadata": {},
   "source": [
    "# Analyse des avions entre eux  \n",
    "Après avoir analysé un unique vols, puis les vols entre eux maintenant on essayeras de déterminer des caractérisiques de l'avion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc149611-8bd5-43f7-8121-eb32bf5505b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# module\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src import * \n",
    "\n",
    "# chemin vers la donnee \n",
    "data_dir = 'C:/Users/felix/PycharmProjects/pythonProject1/MACS3-Statistiques-Descriptives-TDs/data/archive/'\n",
    "filelist = glob.glob(data_dir + '*.h5')\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b5e39-264d-4fdb-82aa-b914235e2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on cree notre dataframe avec DASK\n",
    "ddf1 = lire_hdf_dask(filelist[0], repertoire= data_dir)\n",
    "#on récupère une liste de booleen où chaque composante fait reférance à une partition \n",
    "I = ddf1.map_partitions(lambda df: eliminate_records(df)).compute()\n",
    "#on sélectione dans un nouveau dataframe les partitions qui ne sont pas anormales \n",
    "DDF1=ddf1.partitions[I==False]\n",
    "# on normalise toute les données excepté les variables booleen \n",
    "ddf_norm1 = DDF1.map_partitions(lambda df : normalize(df))\n",
    "\n",
    "ddf2 = lire_hdf_dask(filelist[2], repertoire= data_dir)\n",
    "I = ddf2.map_partitions(lambda df: eliminate_records(df)).compute()\n",
    "DDF2=ddf2.partitions[I==False]\n",
    "ddf_norm2 = DDF2.map_partitions(lambda df : normalize(df))\n",
    "\n",
    "ddf3 = lire_hdf_dask(filelist[3], repertoire= data_dir)\n",
    "I = ddf3.map_partitions(lambda df: eliminate_records(df)).compute()\n",
    "DDF3=ddf3.partitions[I==False]\n",
    "ddf_norm3 = DDF3.map_partitions(lambda df : normalize(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
