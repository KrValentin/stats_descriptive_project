{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Présentations de fonctions utiles lors de l'analyse multi-vols\n",
    "\n",
    "Projet de statistiques descriptives MACS3, dans le cadre du cours de Jérôme Lacaille.\n",
    "\n",
    "_Version 1.0 [27/11/2023] Kraemer Valentin_\n",
    "\n",
    "## Présentation des fonctions d'analyses de dask.dataframe & application au cas classique $N1 = N2 + T1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation des fonctionnnalités proposées \n",
    "\n",
    "Ce notebook a pour objectif de présenter certaines fonctions basées sur le package *dask* pour paralléliser les analyses sur tous les vols d'un même avion. On commencera celui-ci en présentant une analyse déjà vue en cours, à savoir le N1 en fonction du N2 et de la température.\n",
    "\n",
    "\n",
    "**Importation des modules pour l'analyse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# packages utiles \n",
    "import sys, glob, re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# module\n",
    "sys.path.append(\"../\")\n",
    "from src import lire_hdf_dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Récupération de la donnée**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# PARAMETRES DE LA DONNEE \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Avion\u001b[39;00m\n\u001b[0;32m      7\u001b[0m _PLANE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m ddf \u001b[38;5;241m=\u001b[39m lire_hdf_dask(\u001b[43mfilelist\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_PLANE\u001b[49m\u001b[43m]\u001b[49m, repertoire\u001b[38;5;241m=\u001b[39m data_dir)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# chemin vers la donnee \n",
    "data_dir = '/home/valentin/Documents/Cours/MACS/MACS3/madane/data/data_extracted/'\n",
    "filelist = glob.glob(data_dir + '*.h5')\n",
    "\n",
    "# PARAMETRES DE LA DONNEE \n",
    "# Avion\n",
    "_PLANE = 0\n",
    "ddf = lire_hdf_dask(filelist[_PLANE], repertoire= data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implémentation de fonctions d'automatisation \n",
    "\n",
    "1. Fonction de normalisation de la donnée \n",
    "\n",
    "En enlevant les différentes variables boléennes pouvant admettre des divisions par zéro et dont la normalisation n'a pas de sens (pb de type), ainsi qu'en renommant les variables sans leur unités (pour éviter les crochets pour des raisons d'incompatibilités dans les régressions), on définit alors la fonction normalize ci-contre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, l = ['NAIV_1 [bool]', 'NAIV_2 [bool]','PRV_1 [bool]', 'PRV_2 [bool]']):\n",
    "    \"\"\"\n",
    "    @author : Kraemer Valenitn \n",
    "    normalize function \n",
    "\n",
    "    desc : élimination des valeurs boléennes du dataframe de vol et renommage des variables sans les crochets d'unité par souci de comptatibilité python\n",
    "\n",
    "    Input : \n",
    "        df : dataframe d'un vol \n",
    "        l  : (facultatif) liste des colonnes à supprimer du dataframe pour éviter notamment les divisions par zéro\n",
    "\n",
    "    Output : \n",
    "        df_norm : dataframe normalisé. \n",
    "    \"\"\"\n",
    "    if len(l)!=0 :\n",
    "        df=  df.drop(columns = l)\n",
    "    newname = []\n",
    "    for col in df.columns :\n",
    "        newname.append(re.sub(r' \\[.*?\\]', '', col))\n",
    "    X = df.values\n",
    "    X_norm = (X - np.mean(X,axis = 0))/np.std(X, axis = 0)\n",
    "    df_norm = pd.DataFrame(data = X_norm, columns=newname, index= df.index)\n",
    "\n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, le package dask nous permet d'obtenir un dask.dataframe normalisé avant la ligne suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_norm = ddf.map_partitions(lambda df : normalize(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par ailleurs, on définit également une fonction de renommage pour une application non normalisée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(df):\n",
    "    \"\"\"\n",
    "    @author : Kraemer Valenitn \n",
    "    rename function \n",
    "\n",
    "    desc : élimination des valeurs boléennes du dataframe de vol et renommage des variables sans les crochets d'unité par souci de comptatibilité python\n",
    "\n",
    "    Input : \n",
    "        df : dataframe d'un vol \n",
    "\n",
    "    Output : \n",
    "        df_norm : dataframe sans les brackets des unités. \n",
    "    \"\"\"\n",
    "\n",
    "    newname = []\n",
    "    for col in df.columns :\n",
    "        newname.append(re.sub(r' \\[.*?\\]', '', col))\n",
    "    X = df.values\n",
    "    df_norm = pd.DataFrame(data = X, columns=newname, index= df.index)\n",
    "\n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient ainsi un dataframe renommé avec la ligne suivante : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.map_partitions(lambda df : rename(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fonction de regression multi-vols\n",
    "\n",
    "On réalise une surcouche de la fonction **ols** de *statsmodel* afin de stocker ces résultats dans un dictionnaire, dans le but de simplifier la procédure de traitement et d'affichage par la suite.\n",
    "\n",
    "Ainsi, la fonction regression s'écrit de la manière suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(df, formula) :\n",
    "    \"\"\"\n",
    "    @author : Kraemer Valentin \n",
    "    regression function \n",
    "\n",
    "    desc : fonction d'automatisation de la regression utilisable compatible avec la fonction generate_df_reg pour une implémentation sous dask\n",
    "\n",
    "    Input : \n",
    "        df : dataframe d'étude \n",
    "        formula : la formule de regression à appliquer\n",
    "    \n",
    "    Output : \n",
    "        reg_dict : un dictionnaire contenant les informations nécessaires à une analyse multi-vol à savoir \n",
    "            - le R2 de regression                       (R2)\n",
    "            - le nombre d'observation                   (N_observations)\n",
    "            - le test de durbin waston                  (Durbin_Watson)\n",
    "            - la liste des paramètres de regression     (ParamName)\n",
    "            - les valeurs des paramètres de regression  (Paramètres)\n",
    "            - la pvaleur de chaque paramètres           (pvaleur)\n",
    "            - les intervalles de confiances de chq prm  (Intervals)\n",
    "\n",
    "    \"\"\"\n",
    "    df2 = df.copy()\n",
    "    import re \n",
    "    for col in df.columns :\n",
    "        newname = re.sub(r' \\[.*?\\]', '', col)\n",
    "        df2.rename(columns={col:newname}, inplace=True)\n",
    "    model = ols(formula, data = df2).fit()\n",
    "    r2 = model.rsquared\n",
    "    pvals = model.pvalues\n",
    "    IC = model.conf_int(0.05)\n",
    "    n_obs = model.nobs\n",
    "    params_list = model.params\n",
    "    reg_dict = {'R2' :r2, 'pvaleur' : pvals.values, 'N_observations':n_obs, 'Paramètres' : params_list.values, 'Intervals': IC.values, 'ParamName': list(params_list.index) , 'Durbin_Watson' : durbin_watson(model.resid)}\n",
    "    return reg_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rien d'exceptionnel pour le moment.. l'intérêt de cette fonction se trouve dans l'application suivante :\n",
    "\n",
    "En se donnant la formule de regression sur le N1, N2 en fonction de la température, on obtient :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formule de regression\n",
    "formula = \"N1_1 ~ N2_1 + T1_1 \"\n",
    "\n",
    "# application de la regression a tous les vols\n",
    "all_reg = ddf_norm.map_partitions(lambda df : regression(df, formula)).compute()\n",
    "all_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient alors un objet python contenant l'ensemble des dictionnaires obtenus à partir de la fonction de régression précédente. On souhaiterait stocker ces regressions sous la forme d'un dataframe afin de faciliter son analyse et afficher des résultats. \n",
    "\n",
    "Ainsi, on implémente la fonction *generate_df_reg* pour passer le résultat de *all_reg* dans un dataframe :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df_reg (all_reg):\n",
    "    \"\"\"\n",
    "    @author : Kraemer Valentin \n",
    "    generate_df_reg function \n",
    "\n",
    "    desc : génération d'un dataframe contenant les analyses regressives d'un avion sur tous ses vols\n",
    "\n",
    "    Input : \n",
    "        all_reg : liste de dictionnaire de la forme de l'output de manipulate_dataframe.regression;\n",
    "            -> celui ci provient de la sortie de la computation de dask.map_partition(lambda df: regression(df))\n",
    "    \n",
    "    Output : \n",
    "        dataframe contenant toutes les analyses regressives de all_reg stockées sous forme de dataframe pour une meilleure manipulation    \n",
    "    \"\"\"\n",
    "    records = all_reg.index.values\n",
    "    Params = all_reg[0]['ParamName']\n",
    "    R2 = np.empty(len(records))\n",
    "    N_obs= np.empty(len(records))\n",
    "    pvals = np.empty((len(records), len(Params)))\n",
    "    params_val = np.empty((len(records), len(Params)))\n",
    "    IC_0 =  np.empty((len(records), len(Params)))\n",
    "    IC_1 =  np.empty((len(records), len(Params)))\n",
    "    DurbinWatson =  np.empty(len(records))\n",
    "\n",
    "    for i, record in enumerate(records) :\n",
    "        record_dict = all_reg[record]\n",
    "        R2[i] = record_dict['R2']\n",
    "        N_obs[i] = record_dict['N_observations']\n",
    "        pvals[i, :] = record_dict['pvaleur']\n",
    "        params_val[i, :] = record_dict['Paramètres']\n",
    "        IC_0[i,:] = record_dict['Intervals'][:,0]\n",
    "        IC_1[i,:] = record_dict['Intervals'][:,1]\n",
    "        DurbinWatson[i] = record_dict['Durbin_Watson']\n",
    "\n",
    "    df_reg = pd.DataFrame({'record': records, 'R2': R2, 'N_obs': N_obs, 'Durbin_Waston': DurbinWatson}).set_index('record')\n",
    "    for i, param in enumerate(Params) :\n",
    "        df_reg['coeff_'+param] = params_val[:,i]\n",
    "        df_reg['pval_'+param] = pvals[:,i]\n",
    "        df_reg['IC0_'+param] = IC_0[:,i]\n",
    "        df_reg['IC1_'+param] = IC_1[:,i]\n",
    "\n",
    "    return df_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient alors :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = generate_df_reg(all_reg)\n",
    "df_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit alors les fonctions suivante : \n",
    "\n",
    "- afficher_significativite : permettant d'obtenir le $R^2$ de regression ainsi que le nombre de points d'études que l'on a apris en fonction du numéro de vol \n",
    "\n",
    "- afficher_coeff : qui affiche les coefficients de régressions en fonction du numéro de vol\n",
    "\n",
    "Ces fonctions sont implémentées de la manière suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_significativite(df_reg) :\n",
    "    \"\"\"\n",
    "    afficher_siginificativite function \n",
    "    @author : Kraemer Valentin \n",
    "\n",
    "    Input : df_reg : dataframe de regression multi-vols\n",
    "\n",
    "    Output : None\n",
    "\n",
    "    \"\"\"\n",
    "    records = df_reg.index.values\n",
    "    fig, axs = plt.subplots(2, figsize = (10,8))\n",
    "    axs[0].plot(records, df_reg['R2'].values)\n",
    "    axs[1].plot(records, df_reg['N_obs'].values)\n",
    "    axs[0].set_xlabel('records')\n",
    "    axs[0].set_ylabel('R2')\n",
    "    axs[0].set_ylim((0,1))\n",
    "    axs[1].set_xlabel('records')\n",
    "    axs[1].set_ylabel(\"Nombre d'observations\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def afficher_coeff(df_reg,window = 1, tol = 1e-10, norm= True):\n",
    "    \"\"\"\n",
    "    afficher_coeff function\n",
    "    @author : Kraemer Valentin \n",
    "\n",
    "    Input : \n",
    "        df_reg : dataframe de regression multi-vols\n",
    "        window : (default = 1) la fenetre glissante surlaquelle on applique une mediane glissante\n",
    "        tol    : (default = 1e-10) la tolérance au delà de laquelle on n'affiche plus les coefficients car la p-valeur est trop élevée\n",
    "        norm   : (bolean, default = True) : permet d'afficher_coeff avec un y_range compris entre -1 et 1 dans le cas de données normalisées\n",
    "    \"\"\"\n",
    "    l= df_reg.columns\n",
    "    ParamName = [s.split('coeff_')[1] for s in l if 'coeff_' in s]\n",
    "    idx = df_reg.index.values\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i,param in enumerate(ParamName) :\n",
    "        df_param =df_reg.where(df_reg['pval_'+param]<tol)\n",
    "        y_roll = df_param['coeff_'+param].rolling(window=window).median().values\n",
    "        y_up = df_param['IC1_'+param].rolling(window= window).median().values\n",
    "        y_down = df_param['IC0_'+param].rolling(window= window).median().values\n",
    "        # mettre à NAN si la p_valeur depasse un certain seuil \n",
    "        plt.plot(idx, y_roll, label = param)\n",
    "        plt.fill_between(idx,y_up, y_down, alpha = 0.2)\n",
    "    plt.xlabel('record')\n",
    "    plt.ylabel('coefficient de regression')\n",
    "    if norm == True : plt.ylim((-1,1))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple d'application**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_significativite(df_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_coeff(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : Pour le dask.dataframe non normalisé, on obtient le résultat suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formule de regression\n",
    "formula = \"N1_1 ~ N2_1 + T1_1 \"\n",
    "\n",
    "# application de la regression a tous les vols\n",
    "all_reg_no_norm = ddf.map_partitions(lambda df : regression(df, formula)).compute()\n",
    "\n",
    "# dataframe de regression\n",
    "df_reg_no_norm = generate_df_reg(all_reg_no_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage en sortie \n",
    "afficher_significativite(df_reg_no_norm)\n",
    "afficher_coeff(df_reg_no_norm, norm = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas des données non normalisées, on constate de l'importance significative (en amplitude !) de la valeur de l'ordonnée à l'origine, ne permettant pas d'apprécier de manière qualitative de l'évolution des paramètres de regression (autres que l'intercept) au cours des vols. On s'interessera alors à une amélioration de cette fonction d'affichage sur deux graphes différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def afficher_coeff(df_reg,window = 1, tol = 1e-10, norm= True):\n",
    "    \"\"\"\n",
    "    afficher_coeff function\n",
    "    @author : Kraemer Valentin \n",
    "\n",
    "    Input : \n",
    "        df_reg : dataframe de regression multi-vols\n",
    "        window : (default = 1) la fenetre glissante surlaquelle on applique une mediane glissante\n",
    "        tol    : (default = 1e-10) la tolérance au delà de laquelle on n'affiche plus les coefficients car la p-valeur est trop élevée\n",
    "        norm   : (bolean, default = True) : permet d'afficher_coeff avec un y_range compris entre -1 et 1 dans le cas de données normalisées\n",
    "    \"\"\"\n",
    "    \n",
    "    l= df_reg.columns\n",
    "    ParamName = [s.split('coeff_')[1] for s in l if 'coeff_' in s]\n",
    "    if norm != True : ParamName.remove('Intercept')\n",
    "    idx = df_reg.index.values\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i,param in enumerate(ParamName) :\n",
    "        df_param =df_reg.where(df_reg['pval_'+param]<tol)\n",
    "        y_roll = df_param['coeff_'+param].rolling(window=window).median().values\n",
    "        y_up = df_param['IC1_'+param].rolling(window= window).median().values\n",
    "        y_down = df_param['IC0_'+param].rolling(window= window).median().values\n",
    "        plt.plot(idx, y_roll, label = param)\n",
    "        plt.fill_between(idx,y_up, y_down, alpha = 0.2)\n",
    "    plt.xlabel('record')\n",
    "    plt.ylabel('coefficient de regression')\n",
    "    if norm == True : plt.ylim((-1,1))\n",
    "    plt.legend()    \n",
    "    plt.show()\n",
    "    if norm != True : \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        param = 'Intercept'\n",
    "        df_param =df_reg.where(df_reg['pval_'+param]<tol)\n",
    "        y_roll = df_param['coeff_'+param].rolling(window=window).median().values\n",
    "        y_up = df_param['IC1_'+param].rolling(window= window).median().values\n",
    "        y_down = df_param['IC0_'+param].rolling(window= window).median().values\n",
    "        plt.plot(idx, y_roll, label = param)\n",
    "        plt.fill_between(idx,y_up, y_down, alpha = 0.2)\n",
    "        plt.xlabel('record')\n",
    "        plt.ylabel('coefficient de regression')\n",
    "        plt.legend()    \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_coeff(df_reg_no_norm, norm = False, window = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion : Pourquoi avoir implémenté ces fonctions ? \n",
    "\n",
    "Lors de la création de cette méthode, j'ai souhaité étudier la variation des coefficients de regression en fonction de l'utilisation du moteur. Supposé neuf à l'origine, le comportement physique entre les différentes pièces pourrait évoluer en fonction du temps : ainsi, les coefficients de regressions pourraient avoir tendance à décroitre ou croitre significativement. \n",
    "\n",
    "Par ailleurs, cette méthode nous permet d'améliorer considérablement nos prédictions de comportement des différentes variables pour la simulation. En effet, ces coefficients de regressions étant sensiblement constant au cours des vols, on peut alors poser :\n",
    "\n",
    "$$\n",
    "N_{1,norm} = \\alpha N_{2, norm} + \\beta T_{1, norm}\n",
    "$$\n",
    "avec $\\alpha = mean(\\alpha_{reg})$ et $\\beta = mean(\\beta_{reg})$, des valeurs connues et constantes !\n",
    "\n",
    "Ainsi, il suffit de revenir à $N_1$ non normalisé avec un estimateur de variance et de moyenne pour obtenir une prédiction de $N_1$ au cours du temps. \n",
    "\n",
    "En outre, si les parmètres $\\alpha$ et $\\beta$ dépendent du nombre de vol effectué, on peut alors obtenir des résultats plus intéressant qu'une statistique de regression triviale. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
